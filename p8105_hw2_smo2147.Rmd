---
title: "Homework 2 - P8105"
author: "Sergio Ozoria RamÃ­rez (smo2147)"
date: "2025-10-01"
output: github_document
---

# Problem 0

#### Loading necessary packages

```{r setup, message =  FALSE}
library(tidyverse)
library(readxl)
```

# Problem 1

#### Cleaning the National Politician Dataset 

```{r tidying pls dataset, message =  FALSE}
pls_month_df =
  read_csv("./Data/FiveThirtyEight/pols-month.csv", na = c("NA", ".", "")) |> 
  janitor::clean_names() |> 
  separate(mon, sep = "-", into = c("year", "month", "day")) |>
  mutate(across(year:day, as.integer),
         month = factor(month,
                        levels = 1:12,
                        labels = tolower(month.abb))) |> 
  mutate(president = case_when(
         prez_gop == 1 ~ "gop",
         prez_gop == 0 ~ "dem",
         TRUE ~ NA_character_ )) |> 
  relocate(year, month, president) |> 
  select(-day, -prez_gop, -prez_dem) |> 
  arrange(year, month)
```

#### Cleaning the Stock Market Index Dataset 

```{r tidying snp dataset, message =  FALSE}
stock_market_df =
  read_csv("./Data/FiveThirtyEight/snp.csv", na = c("NA", ".", "")) |> 
  janitor::clean_names() |> 
  separate(date, sep = "/", into = c("month", "day", "year")) |> 
  mutate(
    across(month:year, as.integer),
    year = ifelse(
      year <= 49, 
      year + 2000, 
      year + 1900),
    month = factor(month, 
                   levels = 1:12, 
                   labels = tolower(month.abb))) |> 
  relocate(year, month) |> 
  select(-day) |> 
  arrange(year, month)
```

#### Tidying the Unemployment Dataset

```{r tidying unemp dataset, message =  FALSE}
unemp_df =
  read_csv("./Data/FiveThirtyEight/unemployment.csv", na = c("NA", ".", "")) |> 
  janitor::clean_names() |> 
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "unemp_rate") |> 
  mutate(
    year = as.integer(year),
    month = factor(month,
                   levels = tolower(month.abb))) |> 
  arrange(year, month) |> 
  relocate(year, month)
```

#### Merging National Politician, Stock Market, and Unemployment Datasets

```{r tidying merged dataset, message =  FALSE}
pls_snp_unemp_df =
  left_join(
    pls_month_df, stock_market_df, 
    by = c("year", "month")) |>
  left_join(
    unemp_df, 
    by = c("year", "month")) |> 
  arrange(year, month)
```

#### Explanation of Politician, Stock Market, and Unemployment Datasets

###### Description of National Democratic and Republic Politician Dataset

To start with dataset **`pls_month_df`**, it contains information about national politicians who are either democratic or republican across across time. The dataset originally had the **`mon`** variable, indicating the date of count, which I separated into columns **`year`**, **`month`**, and **`day`** using the **`separate`** function. It also had two variables, **`prez_gop`** and **`prez_dem`**, indicating whether sitting president was republican or democratic on the associated date of count, which I mutated into a new variable called **`president`**. After tidying the dataset, the dataset was left with **`r nrow(pls_month_df)`** observations and **`r ncol(pls_month_df)`** variables. The range of years for national politicians goes from **`r pls_month_df |> pull(year) |> min()`** to **`r pls_month_df |> pull(year) |> max()`**, which tell us the year of observation. Along with the **`year`** variable, we get more information from the **`month`** and **`president`** variables, which also indicate the month of observation and indication of whether the president was republican or democratic at the time of observation. The remaining variables in this dataset gives us information about republican and democratic representatives, governors, and senators on the associated year and month of observation. 

###### Description of Standard & Poorâ€™s Stock Market Index Dataset

The **`stock_market_df`** dataset contains information about the market index, which gives you a representative measure of the stock market at the time of observation. The dataset originally had the **`date`** variable, indicating the date of observation, which I separated into columns **`year`**, **`month`**, and **`day`** using the **`separate`** function. After tidying the dataset, the dataset was left with **`r nrow(stock_market_df)`** observations and **`r ncol(stock_market_df)`** variables.  The range of years for the closing values of the S&P stock index goes from **`r stock_market_df |> pull(year) |> min()`** to **`r stock_market_df |> pull(year) |> max()`**, which tell us the year of observation. These variable basically gives us insight on the closing values of the stock market index based on the associated date, as depicted by the **`close`** variable at the end of the **`year`** and **`month`** observations. 

###### Description of Unemployment Rate Dataset

As for the **`unemp_df`** dataset, it contains information about the unemployment rate on the associated year and month. The dataset originally had the number of months as variables, ranging from **`jan`** to **`dec`**, along with the **`year`** variable, totaling **68** observations with **13** variables total. I used the **`pivot_longer`** function to reshape my dataframe from wide to long, creating a new variable called **`month`** and gathering the unemployment rates observations paired with the corresponding month and year of observation on the associated date. After tidying the dataset, the dataset was left with **`r nrow(unemp_df)`** observations and **`r ncol(unemp_df)`** variables.  The range of years for unemployment rates go from **`r unemp_df |> pull(year) |> min()`** to **`r unemp_df |> pull(year) |> max()`**, which tell us the associated year and month on the observed rate.

###### Description of Merged Politician, Stock Market, and Unemployment Datasets

Lastly, we merged the politician, stock market, and employment datasets described above using the **`left_join`** function for the combined dataset **`pls_snp_unemp_df`**. After merging these datasets, we get a year range from  **`r pls_snp_unemp_df |> pull(year) |> min()`** to **`r pls_snp_unemp_df |> pull(year) |> max()`**. It also contains **`r nrow(pls_snp_unemp_df)`**  observations and **`r ncol(pls_snp_unemp_df)`** variables. Key variables that are important to this merged dataset include the **`year`**, **`month`**, **`president`**, **`close`**, and **`unemp_rate`** variables, which provides a big picture overview of what the closing values of the stock market and unemployment rates were for each sitting president, either democratic or republican on the associated year and month.

# Problem 2

#### Cleaning the Mr. Trash Wheel Sheet

```{r cleaning trash wheel dataset}
mr_twheel_df =
  read_excel("./Data/TrashWheel/trashwheel_collection_data.xlsx", 
             sheet = "Mr. Trash Wheel", 
             range = "A2:N710", 
             na = c("NA", ".", "")) |> 
  janitor::clean_names() |>
  select(-month, -year) |> 
  separate(
    date, 
    sep = "-", 
    into = c("year", "month", "day")) |>
  mutate(
    wheel_name = "mr_trash_wheel",
    sports_balls = as.integer(round(sports_balls, 0)), 
    homes_powered = round(homes_powered, 2), 
    across(year:day, as.integer),
    month = factor(month,
                   levels = 1:12,
                   labels = tolower(month.abb))) |> 
  relocate(wheel_name, dumpster) |> 
  filter(!is.na(dumpster))
```


#### Cleaning the Professor Trash Wheel Sheet

```{r cleaning professor trash sheet}
prof_twheel_df =
  read_excel("./Data/TrashWheel/trashwheel_collection_data.xlsx", 
             sheet = "Professor Trash Wheel", 
             range = "A2:M135", 
             na = c("NA", ".", "")) |> 
  janitor::clean_names() |>
  select(-month, -year) |> 
  separate(
    date, 
    sep = "-", 
    into = c("year", "month", "day")) |> 
  mutate(
    wheel_name = "prof_trash_wheel",
    homes_powered = round(homes_powered, 2), 
    across(year:day, as.integer),
    month = factor(month,
                   levels = 1:12,
                   labels = tolower(month.abb))) |> 
  relocate(wheel_name, dumpster) |> 
  filter(!is.na(dumpster))
```

#### Cleaning the Gwynns Falls Trash Wheel Sheet

```{r cleaning gwynns fall sheet}
gwynns_twheel_df =
  read_excel("./Data/TrashWheel/trashwheel_collection_data.xlsx", 
             sheet = "Gwynns Falls Trash Wheel", 
             range = "A2:L352", 
             na = c("NA", ".", "")) |> 
  janitor::clean_names() |>
  select(-month, -year) |> 
  separate(
    date, 
    sep = "-", 
    into = c("year", "month", "day")) |> 
  mutate(
    wheel_name = "gwynns_falls", 
    homes_powered = round(homes_powered, 2), 
    across(year:day, as.integer),
    month = factor(month,
                   levels = 1:12,
                   labels = tolower(month.abb))) |> 
  relocate(wheel_name, dumpster) |> 
  filter(!is.na(dumpster))
```

#### Combining Mister, Professor, and Gwynns Trash Wheel Datasets

```{r combining trash sheets}
twheel_tidy =
  bind_rows(mr_twheel_df, prof_twheel_df, gwynns_twheel_df) |> 
  pivot_longer(
    plastic_bottles:sports_balls,
    names_to = "trash_type",
    values_to = "tt_count"
  )
```

##### Description of Trash Wheel Datasets

The **`twheel_tidy`** dataset contains **`r nrow(twheel_tidy)`** observations and **`r ncol(twheel_tidy)`** variables gathered from three distinct datasets using the **`bind_rows`** function. These datasets were the Mr. Trash Wheel, Professor Trash Wheel, and Gwynns Falls Trash Wheel. The combined dataset was reshaped into a longer format using the **`pivot_longer`** function to organize the trash by type, as depicted in the new variables added in **`twheel_tidy`** (i.e., **`trash_type`** and **`tt_count`**). As a result, the number of rows is larger than the number of original dumpsters. Each record in the dataset includes the wheel name, the associated data of observations, including **`year`**, **`month`**, and **`day`**, the total weight of trash (i.e., **`weight_tons`**), and the type of trash (i.e.,**`trash_type`**) as well as its count (i.e., **`tt_count`**). Altogether, this combined dataset allows for comparisons across wheel and trash types.

###### Total Weight Trash Collected by Professor Trash Wheel

```{r calculating total weight trash by prof trash}
twheel_tidy |> 
  group_by(wheel_name) |> 
  filter(
    wheel_name == "prof_trash_wheel") |> 
  distinct(
    dumpster, year, month, 
    day, weight_tons) |> 
  summarize(
    prof_total_weight = sum(weight_tons, na.rm = TRUE))
```

Based on the available data, the total weight of trash collected by Professor Trash Wheel is **282**. 

###### Total Number of Cigarette Butts Collected by Gwynns

```{r calculating total number of cigs by gwynns}
twheel_tidy |> 
  group_by(wheel_name) |> 
  filter(
    wheel_name == "gwynns_falls", 
    year == "2022", 
    month == "jun", 
    trash_type == "cigarette_butts") |> 
  distinct(
    dumpster, year, month, 
    day, trash_type, tt_count) |> 
  summarize(
    gwynns_total_cigs = sum(tt_count, na.rm = TRUE))
```

Based on the available data, the total number of cigarette butts collected by Gwynns in June of 2022 was **18,120**.

# Problem 3

#### Cleaning Zillow Zipcode Dataset 

```{r cleaning zipcode dataset, message = FALSE}
zillow_codes_df =
  read_csv("./Data/zillow_data/zip_codes.csv", na = c("NA", ".", "")) |> 
  janitor::clean_names() |> 
  separate(file_date, 
           sep = "/", 
           into = c("month", "day", "year")) |> 
  separate_rows(neighborhood, 
                sep = "and ") |> 
  mutate(
    across(year:day, as.integer),
    year = ifelse(
      year <= 49, 
      year + 2000, 
      year + 1900),
    county = case_when(
      county == "Bronx" ~ "bronx_county",
      county == "Kings" ~ "kings_county",
      county == "Queens" ~ "queens_county",
      county == "Richmond" ~ "richmond_county",
      county == "New York" ~ "manhattan_county"),
    neighborhood = neighborhood |> 
      str_to_lower() |> 
      str_trim() |> 
      str_replace_all(" ", "_"),
    month = factor(month,
                   levels = 1:12,
                   labels = tolower(month.abb))) |> 
  relocate(year, month, day, county, neighborhood, zip_code)
```

#### Cleaning Zillow ZORI Dataset 

```{r cleaning zillow zori dataset, message = FALSE}
zillow_zori_df =
  read_csv("./Data/zillow_data/zip_zori_uc_sfrcondomfr_sm_month_NYC.csv",
           na = c("NA", ".", "")) |> 
  janitor::clean_names() |> 
  pivot_longer(
    cols = x2015_01_31:x2024_08_31,
    names_to = "date",
    names_prefix = "x",
    values_to = "rental_price") |> 
  separate(
    date,
    sep = "_", 
    into = c("year", "month", "day")) |> 
  separate(
    metro,
    sep = ",",
    into = c("metro_area", "metro_states")) |> 
  mutate(
    metro_area = metro_area |> 
      str_to_lower() |> 
      str_replace_all(" ", "-"),
    county_name = case_when(
      county_name == "Bronx County" ~ "bronx_county",
      county_name == "Kings County" ~ "kings_county",
      county_name == "Queens County" ~ "queens_county",
      county_name == "Richmond County" ~ "richmond_county",
      county_name == "New York County" ~ "manhattan_county"),
    city = case_when(
      city == "New York" ~ "new_york"),
    across(year:day, as.integer),
    month = factor(
      month,
      levels = 1:12,
      labels = tolower(month.abb))) |> 
  rename(zip = region_name) |> 
  select(-region_type, -state_name) |> 
  relocate(
    zip, city, county_name, 
    state, year, 
    month, day, rental_price)
```

